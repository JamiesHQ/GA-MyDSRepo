{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out t-sne tutorial here\n",
    "\n",
    "http://distill.pub/2016/misread-tsne/\n",
    "\n",
    "\n",
    "### Jupyter notebook discussed here\n",
    "\n",
    "https://blog.sourced.tech/post/lapjv/\n",
    "\n",
    "\n",
    "### direct github here\n",
    "\n",
    "https://gist.github.com/vmarkovtsev/74e3a973b19113047fdb6b252d741b42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "%pylab inline\n",
    "import pickle\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home='/Users/Reid/DS-SF-32/lessons/stolen_t-sne_tutorial/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist[\"data\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take random 2500 images - we will project them to 50 x 50 grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 50\n",
    "N = size * size\n",
    "data, target = shuffle(mnist[\"data\"], mnist[\"target\"], random_state=777, n_samples=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA them to 100 dimensions and run t-SNE. Normalize the results to [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_100 = PCA(n_components=100).fit_transform(data.astype(float32) / 255)\n",
    "embeddings = TSNE(init=\"pca\", random_state=777, verbose=2).fit_transform(data_100)\n",
    "embeddings -= embeddings.min(axis=0)\n",
    "embeddings /= embeddings.max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scatter plot to visualize the embedded samples. We see that t-SNE did it's job well and there are clear digit clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rcParams[\"figure.figsize\"] = (17, 9)\n",
    "scatter(embeddings[:, 0], embeddings[:, 1], c=target)\n",
    "my_colorbar = colorbar(fraction=0.05, pad = 0.0125)\n",
    "xticks([]); yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the scatter plot looks like if we draw original images with alpha mask instead of dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "gca().set_facecolor(\"black\")\n",
    "rcParams[\"figure.figsize\"] = (16, 9)\n",
    "for pos, img in zip(embeddings, data):\n",
    "    img = img.reshape(28, 28)\n",
    "    img = stack((img, img, img, ones((28, 28), dtype=uint8) * 255), axis=-1)\n",
    "    img[img[:, :, 0] == 0] = 0\n",
    "    ab = AnnotationBbox(OffsetImage(img), 0.03 + pos * 0.94, xycoords=\"axes fraction\", frameon=False)\n",
    "    gca().add_artist(ab)\n",
    "xticks([]); yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a regular grid with 2500 dots (54 by 54) on which we will project the samples after t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "grid = dstack(meshgrid(linspace(0, 1, size), linspace(0, 1, size))).reshape(-1, 2)\n",
    "rcParams[\"figure.figsize\"] = (9, 9)\n",
    "scatter(grid[:,0], grid[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the cost matrix - squared L2 distance from every sample to each of the grid nodes. Thus the matrix size is 2500 by 2500. We normalize it to 100000 - this makes Jonker-Volgenant algorithm more numerically stable. Finally, we run [lapjv](https://github.com/src-d/lapjv) and obtain the solution of our linear assignment problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lapjv import lapjv\n",
    "\n",
    "cost_matrix = cdist(grid, embeddings, \"sqeuclidean\").astype(float32)\n",
    "cost_matrix = cost_matrix * (100000 / cost_matrix.max())\n",
    "%time row_asses, col_asses, _ = lapjv(cost_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the visualization of the found solution. Each arrow starts at the original sample and points to the corresponding optimal grid node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_jv = grid[col_asses]\n",
    "pp_cmap = cm.get_cmap(rcParams[\"image.cmap\"])\n",
    "rcParams[\"figure.figsize\"] = (17, 9)\n",
    "for start, end, t in zip(embeddings, grid_jv, target):\n",
    "    arrow(start[0], start[1], end[0] - start[0], end[1] - start[1],\n",
    "          head_length=0.005, head_width=0.005, color=pp_cmap(t / 9), alpha=0.5)\n",
    "colorbar(my_colorbar.mappable, fraction=0.05, pad = 0.0125)\n",
    "xticks([]); yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the final MNIST 2D map. `grid_jv` contains the found optimal coordinates, we iterate it together with the corresponding images. Matplotlib seems to have a bug with AnnotationBbox - the actual OffsetImage size is double of that requested, so we need to scale each to (14, 14) so that they do not overlap. However, most MNIST images do not contain any useful information at the boundaries, so we \"overcommit\" and resize to (20, 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "rcParams[\"figure.figsize\"] = (16, 16)\n",
    "gca().set_facecolor(\"black\")\n",
    "for pos, img in zip(grid_jv, data):\n",
    "    img = Image.fromarray(255 - img.reshape(28, 28)).resize((20, 20), Image.ANTIALIAS)\n",
    "    ab = AnnotationBbox(OffsetImage(img, cmap=\"Greys\"),\n",
    "                        pos * (size - 1) * 28, xycoords=\"data\", frameon=False, box_alignment=(0, 0))\n",
    "    gca().add_artist(ab)\n",
    "xlim(0, (size - 1) * 28 + 16); ylim(0, (size - 1) * 28 + 16)\n",
    "xticks([]); yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
